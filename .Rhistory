runApp()
install.packages("tidyverse")
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
install.packages("shinycssloaders")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
hist(iris$Sepal.Length)
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
install.packages("spacyr")
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
shinyApp(ui = ui, server = server)
shinyApp(ui = ui, server = server)
runApp('saveTest.R')
runApp('saveTest.R')
server <- function(input, output, session) {
output$out <- renderText({
if (input$caps)
toupper(input$txt)
else
input$txt
})
}
runApp('sd.r')
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
load("/home/ogulcan/bio.rda")
aidata <-
aidata <- aidata%>% separate(Date,c("day","month","year"),remove = F)
remove(aidata)
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
r = 5
5
5 <- r
r <- 5
r
66 = 5
66 = r
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
library(shiny); runApp('saveTest.R')
remove(r,x,y)
remove(a,KWsubset)
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
#######MAKE A CORPUS######3
#0.0 find a csv  upload template from SHINY
#0.1 read the text into quanteda, availabale formats are:
#(.txt) ; (.csv) ;XML ; JSON; data Facebook API, in JSON ;data from  Twitter API,
#from a drop down menu, user can select the suitable format
#READ COMMAND: text_field= is where the text is: ie. title, contenet, news etc...
#hence we need another configuration button after the formatof the corpus is selected:
#your text is in column: ....
aidata <- readtext("AI_peopleschina.csv", text_field="content")
# following command turns the file into a corpus:
aicorp <- corpus(aidata) #makes a corpus
aicorp
View(aidata)
aicorp$year
aicorp
View(aicorp)
aicorp$metadata
aicorp$metadata(:5)
aicorp$metadata(5)
aicorp$metadata()
aicorp$metadata
aicorp$settings
View(aicorp)
aicorp$documents
aicorp$documents$year
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
remove(aicorp,aidata)
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
library(shiny); runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
#######MAKE A CORPUS######3
#0.0 find a csv  upload template from SHINY
#0.1 read the text into quanteda, availabale formats are:
#(.txt) ; (.csv) ;XML ; JSON; data Facebook API, in JSON ;data from  Twitter API,
#from a drop down menu, user can select the suitable format
#READ COMMAND: text_field= is where the text is: ie. title, contenet, news etc...
#hence we need another configuration button after the formatof the corpus is selected:
#your text is in column: ....
aidata <- readtext("AI_peopleschina.csv", text_field="content")
# following command turns the file into a corpus:
aicorp <- corpus(aidata) #makes a corpus
#######1. EXPLORE YOUR CORPUS##########
#1.0 this gives a general summary of the corpus and makes a DF for further operations
#1.0.1: calculate readibility: a pulldown menu with configuration: measure= "Flesch.Kincaid" etc.. ;
#remove_hyphens=T, F; min-max sentence length
fk <- textstat_readability(aicorp, "Flesch.Kincaid")
ai15 <- corpus_subset(aicorp, year == 2015)
#1.2 corpus_subset
ai16 <- corpus_subset(aicorp, year == 2016)
#join two corpuses, ie update your corpus, append new elements
aicorp <- aicorp + "newcorp"
aisum <- ai15 + ai16 #this is a working example,
#1.3 concordance: box: enter your keyword, windows=?
options(width = 200)
scikw <- kwic(aicorp, "science")
kwic(aicorp, "scien", valuetype = "regex")
textplot_xray(scikw, sort=T)
#lexical dispersion plot
textplot_xray(kwic(ai15, "science" ), kwic(ai15, "technology" ), sort = T)+
aes(color = keyword) + scale_color_manual(values = c("blue", "red"))
scikw <- kwic(aicorp, "science")
kwic(aicorp, "scien", valuetype = "regex")
######3. DFM  #######
#3.0 raw DFM
#Constructing a document-frequency matrix; this is a quick and dirty solution, needs to be done after careful feature selection
ai.dfm <- dfm(aicorp, remove = stopwords("SMART"), stem = T, remove_punct = T, remove_numbers = T)
ai.dfmw <- dfm_weight(ai.dfm, type ="tfidf" )#"frequency", tf = relfreq, relmaxfreq, logfreq, tfidf
ai.trm <- dfm_trim(ai.dfmw, min_count = 100, max_count = 300,  verbose = T)
topfeatures((ai.dfmw))
textplot_wordcloud(ai.trm, max.words =Inf,  random.order = FALSE,
rot.per = .25, scale = c(2, 0.01),
colors = RColorBrewer::brewer.pal(8,"Dark2"))
#3.2 Grouping
ai.grp <- dfm(aicorp, groups = "year", remove = stopwords("SMART"), remove_punct = TRUE)
textplot_wordcloud(ai.grp, random.color = TRUE, rot.per = .25,
colors = sample(colors()[2:128], 5))
#3.2.1 wordcloud
textplot_wordcloud(ai.grp, comparison = T)
#3.2.3 plot the freq of a term in groups
freq_grouped <- textstat_frequency(ai.dfmw,
groups = "year")
# Filter the term "musk"
fregr <- subset(freq_grouped, feature %in% "musk")
ggplot(fregr,  aes(group, frequency)) +
geom_point()+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# 3.2.5 calculate keyness reference to a group (disciminates the key words according to groups)
#Only select speeches for a group(year, person etc..)
ai.sub <- corpus_subset(aicorp,
year %in% c("2015", "2016"))
# Create a dfm grouped by president
ai.subdfm <- dfm(ai.sub, groups = "year", remove = stopwords("english"),
remove_punct = TRUE)
# Calculate keyness and determine Trump as target group
result_keyness <- textstat_keyness(ai.subdfm, target = "2016")
# Plot estimated word keyness
textplot_keyness(result_keyness)
#####DFM from dictionary categories, this can go to beginning or separate
#make a dictionary
myDict <- dictionary(list(science = c("technology", "scien*", "invent*"),
economy = c("jobs", "economy", "business", "grow", "work")))
# set the file location to the correct location on your computer.
#DFM
ai.dict <- dfm(aicorp, groups = "year",  remove = stopwords("english"), remove_punct = TRUE, dictionary =myDict)
topfeatures(ai.dict)
#Baloonplot for , but can alos add other plots
dt <- as.table(as.matrix(ai.dict))
library("gplots")
balloonplot(t(dt), main ="Words", xlab ="", ylab="",
label = FALSE, show.margins = FALSE)
#4. KNOWLEDGE DISCOVERY: SIMILARITIES
ai2016 <- corpus_subset(aicorp, year==2016)
ai2016dfm <- dfm(ai2016, stem = T, remove = stopwords("english"), remove_punct=T)
d <- textstat_simil(dfm_weight(ai2016dfm, "tfidf"), margin="features", method="cosine")
textstat_dist(dfm_weight(ai2016dfm, "tfidf"), margin="documents", method="euclidean")
ai.trm <- dfm_trim(ai.dfmw, min_count = 100, max_count = 200,  verbose = T)
d <- textstat_simil(dfm_weight(ai.trm, "tfidf"), margin="features", method="cosine")
#CLUSTERING
library(dendextend)
hc_res <- hclust(d, method = "ward.D")
dend <- as.dendrogram(hc_res)
plot(dend,
horiz =  TRUE,  nodePar = list(cex = .007))
#4. KNOWLEDGE DISCOVERY: SIMILARITIES
ai2016 <- corpus_subset(aicorp, year==2016)
ai2016dfm <- dfm(ai2016, stem = T, remove = stopwords("english"), remove_punct=T)
d <- textstat_simil(dfm_weight(ai2016dfm, "tfidf"), margin="features", method="cosine")
textstat_dist(dfm_weight(ai2016dfm, "tfidf"), margin="documents", method="euclidean")
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
runApp('saveTest.R')
library(shiny); runApp('saveTest.R')
